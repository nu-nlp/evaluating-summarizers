{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9523444",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: packaging in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (2022.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (0.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: pandas in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: multiprocess in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (4.11.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: dill in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: filelock in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyyaml in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from packaging->datasets) (3.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb46726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: regex in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from sacrebleu) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from sacrebleu) (1.21.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from sacrebleu) (0.8.9)\n",
      "Requirement already satisfied: portalocker in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from sacrebleu) (2.4.0)\n",
      "Requirement already satisfied: colorama in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from sacrebleu) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad39b6c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lexrank in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (0.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from lexrank) (0.18.1)\n",
      "Requirement already satisfied: regex>=2017.11.9 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from lexrank) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from lexrank) (1.21.6)\n",
      "Requirement already satisfied: urlextract>=0.7 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from lexrank) (1.5.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from lexrank) (1.7.3)\n",
      "Requirement already satisfied: path.py>=10.5 in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from lexrank) (12.5.0)\n",
      "Requirement already satisfied: path in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from path.py>=10.5->lexrank) (16.4.0)\n",
      "Requirement already satisfied: uritools in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from urlextract>=0.7->lexrank) (4.0.0)\n",
      "Requirement already satisfied: platformdirs in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from urlextract>=0.7->lexrank) (2.5.2)\n",
      "Requirement already satisfied: filelock in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from urlextract>=0.7->lexrank) (3.6.0)\n",
      "Requirement already satisfied: idna in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (from urlextract>=0.7->lexrank) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install lexrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df321654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages (4.64.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76ec3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apatel/miniconda3/envs/summariser/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Reusing dataset cnn_dailymail (/home/apatel/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 142.04it/s]\n",
      "Using custom data configuration default\n",
      "Reusing dataset billsum (/home/apatel/.cache/huggingface/datasets/billsum/default/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959)\n",
      "100%|███████████████████████████████████████████| 3/3 [00:00<00:00, 1207.92it/s]\n",
      "Reusing dataset reddit_tifu (/home/apatel/.cache/huggingface/datasets/reddit_tifu/short/1.1.0/1c73fb08807b54ec26b025829b2a3d90c6f7466dac20801c825571af9514c049)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 754.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "cnndaily = load_dataset('cnn_dailymail', '3.0.0')\n",
    "billsum = load_dataset('billsum')\n",
    "reddit = load_dataset('reddit_tifu', 'short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ec7171-ff0f-4f66-9e1f-cbe355b6104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset reddit_tifu/long (download: 639.54 MiB, generated: 87.72 MiB, post-processed: Unknown size, total: 727.26 MiB) to /home/apatel/.cache/huggingface/datasets/reddit_tifu/long/1.1.0/1c73fb08807b54ec26b025829b2a3d90c6f7466dac20801c825571af9514c049...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset reddit_tifu downloaded and prepared to /home/apatel/.cache/huggingface/datasets/reddit_tifu/long/1.1.0/1c73fb08807b54ec26b025829b2a3d90c6f7466dac20801c825571af9514c049. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 557.23it/s]\n"
     ]
    }
   ],
   "source": [
    "reddit_l = load_dataset('reddit_tifu', 'long')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423b348",
   "metadata": {},
   "source": [
    "### CNN Daily Mail results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83cca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 11490/11490 [01:55<00:00, 99.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "references = []\n",
    "predictions = []\n",
    "start = datetime.now()\n",
    "for instance in tqdm(cnndaily['test']):\n",
    "    query = instance['article']\n",
    "    reference = instance['highlights']\n",
    "    prediction = summarizer.summarize(query)\n",
    "    references.append([[reference]])\n",
    "    predictions.append([prediction])\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce74c90-332e-4917-beec-fe80bfb17161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:55.983729\n"
     ]
    }
   ],
   "source": [
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "18fa2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_tokens = [[[r]] for r in references]\n",
    "predictions_tokens = [[p] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0a5e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_tokens = []\n",
    "prediction_tokens = []\n",
    "for i in range(len(references)):\n",
    "    reference_tokens.append([references[i].split(' ')])\n",
    "    prediction_tokens.append([predictions[i].split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abe0e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "text = predictions[0]\n",
    "tokens = tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696b80f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'chrf', 'code_eval', 'comet', 'competition_math', 'coval', 'cuad', 'exact_match', 'f1', 'frugalscore', 'glue', 'google_bleu', 'indic_glue', 'mae', 'mahalanobis', 'matthews_correlation', 'mauve', 'mean_iou', 'meteor', 'mse', 'pearsonr', 'perplexity', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'ter', 'wer', 'wiki_split', 'xnli', 'xtreme_s']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 6.309932009942896,\n",
       " 'counts': [441472, 194960, 97678, 57874],\n",
       " 'totals': [2371005, 2359515, 2348025, 2336535],\n",
       " 'precisions': [18.61961488904494,\n",
       "  8.262715007109511,\n",
       "  4.160006814237497,\n",
       "  2.4769156036609767],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 2371005,\n",
       " 'ref_len': 737699}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric, list_metrics\n",
    "print(list_metrics())\n",
    "metric = load_metric('sacrebleu', 'cnn_dailymail')\n",
    "# metric.compute(predictions=[[\"I am performing team analysis\"]], references=[[[\"I am performing team analysis\"]]])\n",
    "# metric.compute(predictions=[[\"ant\"], [\"ball bat cat\"], [\"vase van ball\"]], references=[[[\"ant\"]],[[\"ball bat cat\"]],[[\"vase van ball\"]]])\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7985dfd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'chrf', 'code_eval', 'comet', 'competition_math', 'coval', 'cuad', 'exact_match', 'f1', 'frugalscore', 'glue', 'google_bleu', 'indic_glue', 'mae', 'mahalanobis', 'matthews_correlation', 'mauve', 'mean_iou', 'meteor', 'mse', 'pearsonr', 'perplexity', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'ter', 'wer', 'wiki_split', 'xnli', 'xtreme_s']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/jy7xkj_52_z8shcnsslwxfw40000gn/T/ipykernel_27862/4223717978.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bertscore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn_dailymail'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/datasets/metric.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtemp_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompute_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/huggingface/modules/datasets_modules/metrics/bertscore/23c058b03785b916e9331e97245dd43a377e84fb477ebdb444aff40629e99732/bertscore.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, predictions, references, lang, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 )\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         (P, R, F) = self.cached_bertscorer.score(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mcands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/bert_score/scorer.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, cands, refs, verbose, batch_size, return_hash)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0midf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         all_preds = bert_cos_score_idf(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mbert_cos_score_idf\u001b[0;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0msen_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         embs, masks, padded_idf = get_bert_embedding(\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0msen_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         )\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mget_bert_embedding\u001b[0;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             batch_embedding = bert_encode(\n\u001b[0m\u001b[1;32m    408\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_sens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             )\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mbert_encode\u001b[0;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         )\n\u001b[0;32m--> 851\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    525\u001b[0m                 )\n\u001b[1;32m    526\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    528\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 340\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_metric, list_metrics\n",
    "metric = load_metric('bertscore', 'cnn_dailymail')\n",
    "metric.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "658f5265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.20304941492837966, recall=0.5470768318858245, fmeasure=0.2727423973276021), mid=Score(precision=0.20522470515904606, recall=0.549896025884278, fmeasure=0.2746197785157393), high=Score(precision=0.2074230545767761, recall=0.5526244909624248, fmeasure=0.2764987309714956)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.0852720945638325, recall=0.22536057942619028, fmeasure=0.11355126719286165), mid=Score(precision=0.08669817659566426, recall=0.2279327398587372, fmeasure=0.11502039415595744), high=Score(precision=0.08802862789426713, recall=0.23040067596756503, fmeasure=0.11644403848059859)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.1345304087950258, recall=0.36088120910699656, fmeasure=0.17968503707078967), mid=Score(precision=0.13612183306950498, recall=0.36331944867664023, fmeasure=0.18125464408721909), high=Score(precision=0.13765045827866612, recall=0.36566623081908267, fmeasure=0.18270020187384348)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.13432959590539842, recall=0.36094464873950466, fmeasure=0.17961499749816526), mid=Score(precision=0.1360787617223792, recall=0.3633163061733745, fmeasure=0.18124936273051695), high=Score(precision=0.1378272931345361, recall=0.36582959639897983, fmeasure=0.1828797697016261))}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric('rouge')\n",
    "# metric.compute(predictions=[[\"a\"], [\"b\"], [\"v\"]], references=[[['a']],[['b']],[['v']]])\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699421e-ebaf-45ef-afc5-5cc0507b8763",
   "metadata": {},
   "source": [
    "## Lead Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dcab9b2-0eb8-4cfa-91e8-60da5b4d43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "def lead(dataset, length):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for instance in tqdm(dataset['train']):\n",
    "        sentences = sent_tokenize(instance['documents'])\n",
    "        \n",
    "    # summarize and keep track of summary word count\n",
    "        summary = \"\"\n",
    "        sentence_index, summary_word_count = 0, 0\n",
    "\n",
    "        while summary_word_count <= length and sentence_index < len(sentences):\n",
    "            sentence = sentences[sentence_index]\n",
    "            summary += sentence + \" \"\n",
    "            sentence_index += 1\n",
    "            summary_word_count += len(word_tokenize(sentence))\n",
    "        predictions.append([summary.strip()])\n",
    "        references.append([[instance['tldr']]])\n",
    "    return predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c71101f9-ff71-4a0e-82db-aef5360ef581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(metric, predictions, references):\n",
    "    metric = load_metric(metric)\n",
    "    print(metric.compute(predictions=predictions, references=references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa36daac-576c-4e86-8816-c06e47277d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 11490/11490 [00:13<00:00, 860.79it/s]\n"
     ]
    }
   ],
   "source": [
    "p, r = lead(cnndaily, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69798dca-cd6a-42e5-9582-2e94fff8c24a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.3400507411364121, recall=0.4135885467056839, fmeasure=0.361234896239558), mid=Score(precision=0.34230609203393925, recall=0.4162487385505991, fmeasure=0.36330840024114824), high=Score(precision=0.34468493044041304, recall=0.41880820794454054, fmeasure=0.3653851548732092)), 'rouge2': AggregateScore(low=Score(precision=0.1422291358149959, recall=0.1740579493361313, fmeasure=0.15126558460150766), mid=Score(precision=0.14418077470988894, recall=0.1764227451949611, fmeasure=0.15312652358368323), high=Score(precision=0.14616277136258826, recall=0.1788546979798391, fmeasure=0.15510614804864395)), 'rougeL': AggregateScore(low=Score(precision=0.21376032223790262, recall=0.2647797409833294, fmeasure=0.2288824094264809), mid=Score(precision=0.21559237062242012, recall=0.26697030394002563, fmeasure=0.23064026951070044), high=Score(precision=0.21732391566602807, recall=0.26932865363811725, fmeasure=0.23231099248528023)), 'rougeLsum': AggregateScore(low=Score(precision=0.21364803717718336, recall=0.26476636025570843, fmeasure=0.22886685644519353), mid=Score(precision=0.21556838870560235, recall=0.2671148874826267, fmeasure=0.23063209294868056), high=Score(precision=0.2173570640055185, recall=0.269264040472296, fmeasure=0.23235032926307797))}\n"
     ]
    }
   ],
   "source": [
    "metrics('rouge', p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ada17ed-9d0a-4f0a-903e-2955505bed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3269/3269 [00:08<00:00, 388.57it/s]\n"
     ]
    }
   ],
   "source": [
    "p, r = lead(billsum, 179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e94384bd-1e52-4126-9e32-7cc46b384ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 9.303562244551324, 'counts': [284562, 106387, 56703, 32283], 'totals': [932300, 929031, 925762, 922493], 'precisions': [30.522578569130108, 11.451393979318237, 6.125008371482087, 3.499538749887533], 'bp': 1.0, 'sys_len': 932300, 'ref_len': 693288}\n"
     ]
    }
   ],
   "source": [
    "metrics('sacrebleu', p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "582ba4d0-f4bb-4120-981c-bcc25643c33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.35678737497301916, recall=0.4611507690508963, fmeasure=0.3617973278497395), mid=Score(precision=0.36212056800587106, recall=0.46708819173245725, fmeasure=0.36557816577612784), high=Score(precision=0.3679165601731733, recall=0.47332139835452497, fmeasure=0.3695181192435316)), 'rouge2': AggregateScore(low=Score(precision=0.14453504922988075, recall=0.19460248433791758, fmeasure=0.14801563328860443), mid=Score(precision=0.14809491949842363, recall=0.19910578445898047, fmeasure=0.15107080861484976), high=Score(precision=0.1514268628841941, recall=0.2038645466230141, fmeasure=0.15408240124725953)), 'rougeL': AggregateScore(low=Score(precision=0.21979995815647718, recall=0.29927745186165317, fmeasure=0.226508601195775), mid=Score(precision=0.2231665737278232, recall=0.3040965371718626, fmeasure=0.2293135935147173), high=Score(precision=0.22646114003391404, recall=0.3091233420140177, fmeasure=0.23225191558151045)), 'rougeLsum': AggregateScore(low=Score(precision=0.2198055552389813, recall=0.2989129315509987, fmeasure=0.22661484379888353), mid=Score(precision=0.2232639201657533, recall=0.3040886536621742, fmeasure=0.2294669831858837), high=Score(precision=0.2268886328928413, recall=0.30944385630362936, fmeasure=0.2324364821774598))}\n"
     ]
    }
   ],
   "source": [
    "metrics('rouge', p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "690494b0-1b01-45e3-b41d-490d93e42a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 42139/42139 [00:33<00:00, 1239.48it/s]\n"
     ]
    }
   ],
   "source": [
    "p, r = lead(reddit_l, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62f32ae7-fb4b-4a57-a1aa-e9e65fcff528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 2.107068134414731, 'counts': [337696, 67850, 23724, 2538], 'totals': [1690414, 1648275, 1606136, 1563997], 'precisions': [19.977118031440817, 4.116424747084073, 1.4770853775769923, 0.16227652610586848], 'bp': 1.0, 'sys_len': 1690414, 'ref_len': 1115133}\n"
     ]
    }
   ],
   "source": [
    "metrics('sacrebleu', p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84a429fe-036a-4cb3-9813-c79c56d7db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.1290154604088615, recall=0.20295169788895498, fmeasure=0.14459886445156672), mid=Score(precision=0.12988456278688804, recall=0.20416864043513872, fmeasure=0.14543274284896096), high=Score(precision=0.13074385929478322, recall=0.205424361433069, fmeasure=0.14622529810218984)), 'rouge2': AggregateScore(low=Score(precision=0.01698663989880662, recall=0.027694217222659006, fmeasure=0.019068816717172817), mid=Score(precision=0.017349972646377332, recall=0.028271383013463616, fmeasure=0.019453276246343954), high=Score(precision=0.017706847678193367, recall=0.028832242183375125, fmeasure=0.019834814899203003)), 'rougeL': AggregateScore(low=Score(precision=0.0931690427997301, recall=0.1519603280779647, fmeasure=0.1056582703515423), mid=Score(precision=0.09380437409886067, recall=0.15292040870004453, fmeasure=0.10625315542341346), high=Score(precision=0.09438538280097448, recall=0.15397021345674108, fmeasure=0.1068594219773597)), 'rougeLsum': AggregateScore(low=Score(precision=0.093191799040699, recall=0.15197017478450142, fmeasure=0.1056472710571237), mid=Score(precision=0.0937890126377111, recall=0.15292136864638584, fmeasure=0.10623809701248879), high=Score(precision=0.09437230120473143, recall=0.15386627803244324, fmeasure=0.10684166906405325))}\n"
     ]
    }
   ],
   "source": [
    "metrics('rouge', p, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70968df",
   "metadata": {},
   "source": [
    "## Billsum Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2745db5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3269/3269 [06:00<00:00,  9.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "bs_references = []\n",
    "bs_predictions = []\n",
    "for instance in tqdm(billsum['test']):\n",
    "    query = instance['text']\n",
    "    reference = instance['summary']\n",
    "    prediction = summarizer.summarize(query)\n",
    "    bs_references.append([[reference]])\n",
    "    bs_predictions.append([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86576de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 8.105573611534249,\n",
       " 'counts': [347492, 139619, 74220, 43066],\n",
       " 'totals': [1381650, 1378381, 1375112, 1371843],\n",
       " 'precisions': [25.150508450041617,\n",
       "  10.129202303281893,\n",
       "  5.397378540802495,\n",
       "  3.1392805153359387],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 1381650,\n",
       " 'ref_len': 693288}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric, list_metrics\n",
    "# print(list_metrics())\n",
    "metric = load_metric('sacrebleu', 'billsum')\n",
    "metric.compute(predictions=bs_predictions, references=bs_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4234f625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.29366946733775157, recall=0.5112937396967577, fmeasure=0.3428276667587242), mid=Score(precision=0.29877202660420865, recall=0.5157646991919496, fmeasure=0.34676238323844577), high=Score(precision=0.30374532123829495, recall=0.5199161967116457, fmeasure=0.35060077919906835)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.12427429834323754, recall=0.21326877013405474, fmeasure=0.14384972348842248), mid=Score(precision=0.12712790886309727, recall=0.2165711503434628, fmeasure=0.1462389284759088), high=Score(precision=0.12980079475252576, recall=0.22009962568757668, fmeasure=0.1486345829933406)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.17624643817551147, recall=0.3169406359766278, fmeasure=0.2068998380791264), mid=Score(precision=0.17928482519952144, recall=0.32036665235190565, fmeasure=0.20935721845179955), high=Score(precision=0.18243061526196488, recall=0.3237740310564653, fmeasure=0.2117242841424929)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.17631269144072959, recall=0.31676922555556464, fmeasure=0.20707030591250114), mid=Score(precision=0.17937936410582642, recall=0.32025999970664343, fmeasure=0.20942894760977526), high=Score(precision=0.18259996068275997, recall=0.32375462293059715, fmeasure=0.21179671213073029))}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric('rouge', 'billsum')\n",
    "metric.compute(predictions=bs_predictions, references=bs_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ea542-15a6-49bd-a513-9063058604e7",
   "metadata": {},
   "source": [
    "### Reddit Tifu long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "61f3f3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title'],\n",
       "    num_rows: 79740\n",
       "})"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in reddit['train']:\n",
    "#     print(i)\n",
    "reddit_l['train']\n",
    "# reddit_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7140424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████▏       | 33000/42139 [02:59<00:53, 170.07it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "rt_references = []\n",
    "rt_predictions = []\n",
    "for instance in tqdm(reddit_l['train']):\n",
    "    query = instance['documents']\n",
    "    reference = instance['tldr']\n",
    "    prediction = summarizer.summarize(query)\n",
    "    rt_references.append([[reference]])\n",
    "    rt_predictions.append([prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7034c446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.0934596613112226,\n",
       " 'counts': [631636, 137593, 46778, 10438],\n",
       " 'totals': [7501362, 7421622, 7341882, 7262142],\n",
       " 'precisions': [8.420284209720847,\n",
       "  1.8539478297331768,\n",
       "  0.6371390877706833,\n",
       "  0.1437316978929908],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 7501362,\n",
       " 'ref_len': 1227936}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric('sacrebleu', 'reddit_tifu')\n",
    "metric.compute(predictions=rt_predictions, references=rt_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "529fd7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.05523798696925347, recall=0.20401740340951258, fmeasure=0.07890371367443742), mid=Score(precision=0.05575873675325173, recall=0.20550285954471845, fmeasure=0.07955652864490603), high=Score(precision=0.056299808237724465, recall=0.20708013464007252, fmeasure=0.08021896320345584)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.011364385652004866, recall=0.04279479796691269, fmeasure=0.016226901198465468), mid=Score(precision=0.011544961509948444, recall=0.043348103911979505, fmeasure=0.016444098951665286), high=Score(precision=0.011737295961418669, recall=0.043930011353607044, fmeasure=0.016688435698417936)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.038971708600889374, recall=0.14724522135972978, fmeasure=0.055704606725571364), mid=Score(precision=0.039360320202898445, recall=0.14841679282874598, fmeasure=0.056175743461478765), high=Score(precision=0.03976735124406718, recall=0.14967170485257703, fmeasure=0.056693035839949925)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.03896737672895003, recall=0.14712782071499184, fmeasure=0.05568514274985345), mid=Score(precision=0.039365557950179916, recall=0.14840958549712802, fmeasure=0.05617946201680732), high=Score(precision=0.039733070624821475, recall=0.1495963420338619, fmeasure=0.05664317899255021))}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric('rouge', 'reddit_tifu')\n",
    "metric.compute(predictions=rt_predictions, references=rt_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af560ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric(name: \"bleu\", features: {'predictions': Sequence(feature=Value(dtype='string', id='token'), length=-1, id='sequence'), 'references': Sequence(feature=Sequence(feature=Value(dtype='string', id='token'), length=-1, id='sequence'), length=-1, id='references')}, usage: \"\"\"\n",
      "Computes BLEU score of translated segments against one or more references.\n",
      "Args:\n",
      "    predictions: list of translations to score.\n",
      "        Each translation should be tokenized into a list of tokens.\n",
      "    references: list of lists of references for each translation.\n",
      "        Each reference should be tokenized into a list of tokens.\n",
      "    max_order: Maximum n-gram order to use when computing BLEU score.\n",
      "    smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
      "Returns:\n",
      "    'bleu': bleu score,\n",
      "    'precisions': geometric mean of n-gram precisions,\n",
      "    'brevity_penalty': brevity penalty,\n",
      "    'length_ratio': ratio of lengths,\n",
      "    'translation_length': translation_length,\n",
      "    'reference_length': reference_length\n",
      "Examples:\n",
      "\n",
      "    >>> predictions = [\n",
      "    ...     [\"hello\", \"there\", \"general\", \"kenobi\"],                             # tokenized prediction of the first sample\n",
      "    ...     [\"foo\", \"bar\", \"foobar\"]                                             # tokenized prediction of the second sample\n",
      "    ... ]\n",
      "    >>> references = [\n",
      "    ...     [[\"hello\", \"there\", \"general\", \"kenobi\"], [\"hello\", \"there\", \"!\"]],  # tokenized references for the first sample (2 references)\n",
      "    ...     [[\"foo\", \"bar\", \"foobar\"]]                                           # tokenized references for the second sample (1 reference)\n",
      "    ... ]\n",
      "    >>> bleu = datasets.load_metric(\"bleu\")\n",
      "    >>> results = bleu.compute(predictions=predictions, references=references)\n",
      "    >>> print(results[\"bleu\"])\n",
      "    1.0\n",
      "\"\"\", stored examples: 0)\n"
     ]
    }
   ],
   "source": [
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9de67",
   "metadata": {},
   "source": [
    "## Lexrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcbd7c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/apatel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexrank import STOPWORDS, LexRank\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# word_counts, doc, summary, summary time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f61d8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document level median length\n",
    "def lexrank(dataset, length):\n",
    "    start = datetime.now()\n",
    "    lxr = LexRank(text, stopwords=STOPWORDS['en'])\n",
    "    # math.ceil(cnndataset)/median sentence length\n",
    "    \n",
    "    from nltk import tokenize\n",
    "    references = []\n",
    "    predictions = []\n",
    "    for instance in tqdm(dataset['test']):\n",
    "        query = instance['article']\n",
    "        reference = instance['highlights']\n",
    "        sentences = tokenize.sent_tokenize(query)\n",
    "        prediction = lxr.get_summary(sentences, summary_size=5, threshold=None)\n",
    "        references.append([[reference]])\n",
    "        predictions.append([prediction])\n",
    "    end = datetime.now()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15aaab-e3d3-4df4-9476-f32a6bdc8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r = lexrank(cnndaily, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb903719-8e68-49a7-8117-26da4e550ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics('sacrebleu', p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e2996e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 7.071632497961682,\n",
       " 'counts': [383173, 145379, 78918, 47834],\n",
       " 'totals': [1720158, 1708668, 1697178, 1685688],\n",
       " 'precisions': [22.275453766456337,\n",
       "  8.508323442588027,\n",
       "  4.649954218119726,\n",
       "  2.837654417662106],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 1720158,\n",
       " 'ref_len': 737699}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('sacrebleu', 'cnn_dailymail')\n",
    "metric.compute(predictions=cnnpredictions_t, references=cnnreferences_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f28a8e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.2149415635760081, recall=0.5021878634020653, fmeasure=0.29097057246558644), mid=Score(precision=0.21662229788452544, recall=0.5049621296342061, fmeasure=0.2927360223608766), high=Score(precision=0.2181612414574238, recall=0.5077388949018342, fmeasure=0.2943686541346999)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.0874714252645371, recall=0.20820342979035544, fmeasure=0.1191443505333403), mid=Score(precision=0.0886568907883392, recall=0.21095542142136708, fmeasure=0.12061179814482456), high=Score(precision=0.08999349528756678, recall=0.21364179294930036, fmeasure=0.12225710350723286)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.13708786781427879, recall=0.3259230987142806, fmeasure=0.1865006127540178), mid=Score(precision=0.13818253897149207, recall=0.3282953782368314, fmeasure=0.1877721503732314), high=Score(precision=0.1393212275462485, recall=0.33081009499539116, fmeasure=0.18913822705492145)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.13705560175285308, recall=0.32577492988882006, fmeasure=0.18639826740776813), mid=Score(precision=0.13820371032479647, recall=0.32824222028839734, fmeasure=0.1877364328880671), high=Score(precision=0.1393272644967915, recall=0.3306123127511244, fmeasure=0.18908769745743723))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric('rouge', 'cnn_dailymail')\n",
    "metric.compute(predictions=cnnpredictions_t, references=cnnreferences_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7d29442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3269/3269 [00:00<00:00, 9482.29it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "documents are not informative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/jy7xkj_52_z8shcnsslwxfw40000gn/T/ipykernel_27862/22861806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLexRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/lexrank/algorithms/summarizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, stopwords, keep_numbers, keep_emails, keep_urls, include_new_words)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_new_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minclude_new_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     def get_summary(\n",
      "\u001b[0;32m/Applications/anaconda3/envs/git-basics/lib/python3.9/site-packages/lexrank/algorithms/summarizer.py\u001b[0m in \u001b[0;36m_calculate_idf\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbags_of_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'documents are not informative'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mdoc_number_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbags_of_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: documents are not informative"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "for instance in tqdm(billsum['test']):\n",
    "    query = instance['text']\n",
    "    text.append(query)\n",
    "    \n",
    "lxr = LexRank(text, stopwords=STOPWORDS['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "cnnreferences = []\n",
    "cnnpredictions = []\n",
    "for instance in tqdm(dataset['test']):\n",
    "    query = instance['text']\n",
    "    reference = instance['summary']\n",
    "    sentences = tokenize.sent_tokenize(reference)\n",
    "    print(sentences)\n",
    "    prediction = lxr.get_summary(sentences, summary_size=55, threshold=None)\n",
    "    cnnreferences.append(reference)\n",
    "    cnnpredictions.append(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
